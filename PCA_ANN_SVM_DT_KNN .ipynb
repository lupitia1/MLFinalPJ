{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e625ac9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "025616e7",
   "metadata": {},
   "source": [
    "#  Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "168190c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All required packages are already installed.\n"
     ]
    }
   ],
   "source": [
    "# skip reinstalling packages we already have\n",
    "using Pkg\n",
    "\n",
    "pkgs = [\n",
    "    \"MLJ\", \"MLJBase\", \"MLJModels\", \"MLJEnsembles\", \"MLJLinearModels\",\n",
    "    \"DecisionTree\", \"MLJDecisionTreeInterface\", \"NaiveBayes\", \n",
    "    \"MLJNaiveBayesInterface\", \"EvoTrees\", \"CategoricalArrays\", \"Random\",\n",
    "    \"LIBSVM\", \"MLJLIBSVMInterface\", \"Plots\", \"MLJModelInterface\",\n",
    "    \"CSV\", \"DataFrames\", \"UrlDownload\", \"XGBoost\",\"MultivariateStats\",\"PrettyTables\"\n",
    "]\n",
    "\n",
    "# Filter out packages already installed\n",
    "missing_pkgs = filter(pkg -> !(pkg in keys(Pkg.project().dependencies)), pkgs)\n",
    "\n",
    "if !isempty(missing_pkgs)\n",
    "    println(\"Installing missing packages: \", missing_pkgs)\n",
    "    Pkg.add(missing_pkgs)\n",
    "else\n",
    "    println(\" All required packages are already installed.\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb836ae",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a512caef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using CSV, DataFrames, Random\n",
    "using Flux\n",
    "using CategoricalArrays\n",
    "using Plots\n",
    "using Random\n",
    "using Statistics\n",
    "using DataFrames\n",
    "using MLJ\n",
    "using MLJBase\n",
    "import Logging\n",
    "using DataFrames\n",
    "Logging.disable_logging(Logging.Info)\n",
    "\n",
    "#Load your library of functions\n",
    "include(\"utils.2.2.jl\")\n",
    "# Set a global random seed for reproducibility\n",
    "Random.seed!(42)\n",
    "\n",
    "# --- Accuracy function ---\n",
    "#accuracy(pred::Vector{Int}, truth::Vector{Int}) = mean(pred .== truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8851a7ca",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c71d5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = CSV.read(\"./data/updated_pollution_dataset.csv\", DataFrame)\n",
    "size(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca8ebdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of df:\n",
      "\u001b[1m5×10 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m Temperature \u001b[0m\u001b[1m Humidity \u001b[0m\u001b[1m PM2.5   \u001b[0m\u001b[1m PM10    \u001b[0m\u001b[1m NO2     \u001b[0m\u001b[1m SO2     \u001b[0m\u001b[1m CO      \u001b[0m\u001b[1m Proximity_to_Industrial_Areas \u001b[0m\u001b[1m Population_Density \u001b[0m\u001b[1m Air Quality \u001b[0m\n",
      "     │\u001b[90m Float64     \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64                       \u001b[0m\u001b[90m Int64              \u001b[0m\u001b[90m String15    \u001b[0m\n",
      "─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   1 │        29.8      59.1      5.2     17.9     18.9      9.2     1.72                            6.3                 319  Moderate\n",
      "   2 │        28.3      75.6      2.3     12.2     30.8      9.7     1.64                            6.0                 611  Moderate\n",
      "   3 │        23.1      74.7     26.7     33.8     24.4     12.6     1.63                            5.2                 619  Moderate\n",
      "   4 │        27.1      39.1      6.1      6.3     13.5      5.3     1.15                           11.1                 551  Good\n",
      "   5 │        26.5      70.7      6.9     16.0     21.9      5.6     1.01                           12.7                 303  GoodColumn 10 name: Air Quality\n",
      "Labels: String15[\"Good\", \"Hazardous\", \"Moderate\", \"Poor\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5000×9 Matrix{Float32}:\n",
       " 29.8  59.1    5.2   17.9  18.9   9.2  1.72   6.3  319.0\n",
       " 28.3  75.6    2.3   12.2  30.8   9.7  1.64   6.0  611.0\n",
       " 23.1  74.7   26.7   33.8  24.4  12.6  1.63   5.2  619.0\n",
       " 27.1  39.1    6.1    6.3  13.5   5.3  1.15  11.1  551.0\n",
       " 26.5  70.7    6.9   16.0  21.9   5.6  1.01  12.7  303.0\n",
       " 39.4  96.6   14.6   35.5  42.9  17.9  1.82   3.1  674.0\n",
       " 41.7  82.5    1.7   15.8  31.1  12.7  1.8    4.6  735.0\n",
       " 31.0  59.6    5.0   16.8  24.2  13.6  1.38   6.3  443.0\n",
       " 29.4  93.8   10.3   22.7  45.1  11.8  2.03   5.4  486.0\n",
       " 33.2  80.5   11.1   24.4  32.0  15.3  1.69   4.9  535.0\n",
       "  ⋮                               ⋮                \n",
       " 31.8  80.2   22.4   34.1  29.7   4.9  1.22   9.4  580.0\n",
       " 29.8  56.7    6.8   14.0  23.0   4.5  1.1   11.4  567.0\n",
       " 34.9  77.7   32.3   47.1  17.4  11.5  1.63   8.8  541.0\n",
       " 31.1  61.0   27.1   31.1  13.0   3.8  0.98  13.4  278.0\n",
       " 40.6  74.1  116.0  126.7  45.5  25.7  2.11   2.8  765.0\n",
       " 28.1  96.9    6.9   25.0  25.3  10.8  1.54   5.7  709.0\n",
       " 25.9  78.2   14.2   22.1  34.8   7.8  1.63   9.6  379.0\n",
       " 25.3  44.4   21.4   29.0  23.7   5.7  0.89  11.6  241.0\n",
       " 24.1  77.9   81.7   94.3  23.2  10.5  1.38   8.3  461.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = CSV.read(\"./data/updated_pollution_dataset.csv\", DataFrame)\n",
    "\n",
    "# Some log\n",
    "println(\"First 5 rows of df:\")\n",
    "show(df[1:5, :], allcols=true)\n",
    "\n",
    "\n",
    "# Convert column 10 to categorical (in-place!)\n",
    "df[!, 10] = categorical(df[!, 10])\n",
    "\n",
    "# Get the column name as string\n",
    "col10_name = string(names(df)[10])\n",
    "println(\"Column 10 name: \", col10_name)\n",
    "\n",
    "# Extract labels (categories) as strings\n",
    "label_names = levels(df[!, 10])\n",
    "println(\"Labels: \", label_names)\n",
    "\n",
    "# Extract the integer codes of the categories\n",
    "targets = Float32.(levelcode.(df[!, 10]))\n",
    "inputs  = Matrix{Float32}(df[:, 1:9])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aad3189",
   "metadata": {},
   "source": [
    "# Prepare data for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccd2a455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: 2000\n",
      "Validation indices: 1500\n",
      "Test indices: 1500\n",
      "df size: (5000, 10)\n",
      "\n",
      "\n",
      "First 5 targets:\n",
      "Float32[3.0, 3.0, 3.0, 1.0, 1.0]\n",
      "Training inputs (first 5 rows):\n",
      "Float32[22.9, 50.0, 19.2, 23.4, 18.8, 6.0, 0.95, 12.2, 225.0]\n",
      "Float32[36.8, 73.6, 36.0, 51.2, 24.5, 11.2, 1.53, 6.0, 630.0]\n",
      "Float32[30.1, 49.0, 7.7, 14.5, 20.2, 7.6, 0.98, 11.0, 465.0]\n",
      "Float32[46.8, 93.8, 11.8, 25.4, 33.8, 28.7, 3.27, 3.7, 589.0]\n",
      "Float32[26.8, 55.7, 0.3, 6.2, 17.3, 5.6, 0.94, 11.4, 425.0]\n",
      "import MLJMultivariateStatsInterface ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLJMultivariateStatsInterface.PCA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "N = size(df, 1)\n",
    "trainIdx, valIdx, testIdx = holdOut(N, 0.3, 0.3)\n",
    "#trainIdx, testIdx = holdOut(N, 0.3)\n",
    "println(\"Train indices: \", length(trainIdx))\n",
    "println(\"Validation indices: \", length(valIdx))\n",
    "println(\"Test indices: \", length(testIdx))\n",
    "println(\"df size: \", size(df))\n",
    "\n",
    "trainingInputs  = inputs[trainIdx, :]\n",
    "valInputs       = inputs[valIdx, :]\n",
    "testInputs      = inputs[testIdx, :]\n",
    "\n",
    "trainingTargets = targets[trainIdx]\n",
    "valTargets      = targets[valIdx]\n",
    "testTargets     = targets[testIdx]\n",
    "\n",
    "\n",
    "println(\"\\n\\nFirst 5 targets:\")\n",
    "println(targets[1:5])\n",
    "\n",
    "println(\"Training inputs (first 5 rows):\")\n",
    "for i in 1:5\n",
    "    println(trainingInputs[i, :])\n",
    "end\n",
    "\n",
    "\n",
    "# Load PCA\n",
    "PCA        = @load PCA pkg = MultivariateStats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc0c2d",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ce3695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=========== Normalizing Inputs ===========\n",
      "\n",
      "Training inputs after normalization (first 5 rows):\n",
      "Float32[0.19230771, 0.15930234, 0.09411765, 0.099500224, 0.2150313, 0.24694379, 0.1, 0.42731276, 0.046875]\n",
      "Float32[0.50678736, 0.43372092, 0.1764706, 0.22580644, 0.33402923, 0.37408313, 0.29333332, 0.15418501, 0.57421875]\n",
      "Float32[0.35520366, 0.14767443, 0.037745096, 0.05906406, 0.24425888, 0.28606358, 0.110000014, 0.3744493, 0.359375]\n",
      "Float32[0.73303175, 0.6686047, 0.057843138, 0.108587004, 0.5281837, 0.801956, 0.8733333, 0.052863438, 0.5208333]\n",
      "Float32[0.280543, 0.22558141, 0.0014705883, 0.021353928, 0.18371606, 0.23716383, 0.09666667, 0.39207044, 0.30729166]\n",
      "\n",
      "Validation inputs after normalization (first 5 rows):\n",
      "Float32[0.20361993, 0.2, 0.024019608, 0.040890504, 0.18789144, 0.25427872, 0.08666668, 0.5726872, 0.40625]\n",
      "Float32[0.14479639, 0.14186047, 0.078431375, 0.08268969, 0.056367427, 0.1613692, 0.17333333, 0.33920702, 0.31640625]\n",
      "Float32[0.3574661, 0.29999998, 0.19705883, 0.20899591, 0.24634653, 0.4596577, 0.37, 0.11453744, 0.50130206]\n",
      "Float32[0.4683258, 0.4872093, 0.068627454, 0.1390277, 0.41336113, 0.17359413, 0.44333336, 0.052863438, 0.53125]\n",
      "Float32[0.31221724, 0.36976743, 0.035294116, 0.03452976, 0.25678495, 0.21515892, 0.14000003, 0.33920702, 0.24739583]\n",
      "\n",
      "Test inputs after normalization (first 5 rows):\n",
      "Float32[0.16289596, 0.46744186, 0.085784316, 0.091322124, 0.28601253, 0.35696825, 0.12666667, 0.38766518, 0.35416666]\n",
      "Float32[0.40723988, 0.7116279, 0.124509804, 0.18764198, 0.519833, 0.35941324, 0.45666668, 0.092511006, 0.78515625]\n",
      "Float32[0.361991, 0.26511627, 0.019117648, 0.060881414, 0.42588726, 0.400978, 0.34, 0.13656387, 0.38802084]\n",
      "Float32[0.2895928, 0.35000002, 0.063725494, 0.06724216, 0.3131524, 0.22004892, 0.14333336, 0.5066079, 0.3111979]\n",
      "Float32[0.26244345, 0.58720934, 0.41862747, 0.4284416, 0.34029225, 0.19559903, 0.19333334, 0.1277533, 0.38020834]\n",
      "Train inputs range per feature: (Float32[0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0], Float32[1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0])\n",
      "Validation inputs range per feature: (Float32[0.0 0.0 0.0 0.0 0.016701465 0.017114911 0.03000001 0.0 0.0], Float32[0.97963816 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.9739583])\n",
      "Test inputs range per feature: (Float32[0.024886888 0.0 0.0 0.0 0.0 0.0 0.01333334 0.0 0.0026041667], Float32[0.9524887 0.93720937 1.0 1.0 1.0 1.0 1.0 0.845815 0.9557292])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "println(\"\\n\\n=========== Normalizing Inputs ===========\")\n",
    "\n",
    "# Compute normalization parameters from TRAINING set only\n",
    "normParams = calculateMinMaxNormalizationParameters(trainingInputs)\n",
    "\n",
    "# Normalize training set IN PLACE\n",
    "normalizeMinMax!(trainingInputs, normParams)\n",
    "\n",
    "# Normalize validation set in place\n",
    "normalizeMinMax!(valInputs, normParams)\n",
    "\n",
    "# Normalize test set in place\n",
    "#valInputs_normalized = normalizeMinMax(valInputs, normParams)\n",
    "normalizeMinMax!(testInputs, normParams)\n",
    "\n",
    "\n",
    "println(\"\\nTraining inputs after normalization (first 5 rows):\")\n",
    "for i in 1:5\n",
    "    println(trainingInputs[i, :])\n",
    "end\n",
    "\n",
    "println(\"\\nValidation inputs after normalization (first 5 rows):\")\n",
    "for i in 1:5\n",
    "    println(valInputs[i, :])\n",
    "end\n",
    "\n",
    "println(\"\\nTest inputs after normalization (first 5 rows):\")\n",
    "for i in 1:5\n",
    "    println(testInputs[i, :])\n",
    "end\n",
    "\n",
    "\n",
    "# Convert to float32 for Flux compatibility\n",
    "trainingInputs = Float32.(trainingInputs)\n",
    "valInputs = Float32.(valInputs)\n",
    "testInputs = Float32.(testInputs)\n",
    "\n",
    "# Clip values to [0,1] after normalization\n",
    "valInputs .= clamp.(valInputs, 0f0, 1f0)\n",
    "testInputs .= clamp.(testInputs, 0f0, 1f0)\n",
    "\n",
    "\n",
    "# Values should only fall within [0,1]\n",
    "@assert(all(minimum(trainingInputs, dims=1) .== 0))\n",
    "@assert(all(maximum(trainingInputs, dims=1) .== 1))\n",
    "@assert(all(minimum(valInputs, dims=1) .>= 0))\n",
    "@assert(all(maximum(valInputs, dims=1) .<= 1))\n",
    "@assert(all(minimum(testInputs, dims=1) .>= 0))\n",
    "@assert(all(maximum(testInputs, dims=1) .<= 1))\n",
    "\n",
    "\n",
    "println(\"Train inputs range per feature: \", (minimum(trainingInputs, dims=1), maximum(trainingInputs, dims=1)))\n",
    "println(\"Validation inputs range per feature: \", (minimum(valInputs, dims=1), maximum(valInputs, dims=1)))\n",
    "println(\"Test inputs range per feature: \", (minimum(testInputs, dims=1), maximum(testInputs, dims=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f789c2",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60406ebd",
   "metadata": {},
   "source": [
    "## Train ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb976b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJMultivariateStatsInterface ✔\n",
      "\n",
      "==== Starting ANN Experiments ====\n",
      "\n",
      "\n",
      "===== Running ANN with topology = [6, 128, 256] =====\n",
      "\n",
      "=====================================================\n",
      " Model: [6, 128, 256]   | PCA outdim = 6 \n",
      " Hyperparameters: Dict{String, Real}(\"epochs\" => 200, \"learningRate\" => 0.01, \"PCA_outdim\" => 6)\n",
      "=====================================================\n",
      " Accuracy                : 0.9207\n",
      " Error Rate              : 0.0793\n",
      " Sensitivity/Recall      : 0.9207\n",
      " Specificity             : 0.9762\n",
      " PPV                     : 0.9206\n",
      " NPV                     : 0.9781\n",
      " F1 Score                : 0.9205\n",
      "\n",
      "Confusion Matrix:\n",
      "[588 4 0 0; 6 415 0 26; 0 0 128 32; 0 31 20 250]\n",
      "=====================================================\n",
      "\n",
      "┌───────────┬──────┬───────────┬──────────┬──────┐\n",
      "│\u001b[1m           \u001b[0m│\u001b[1m Good \u001b[0m│\u001b[1m Hazardous \u001b[0m│\u001b[1m Moderate \u001b[0m│\u001b[1m Poor \u001b[0m│\n",
      "├───────────┼──────┼───────────┼──────────┼──────┤\n",
      "│\u001b[1m      Good \u001b[0m│  588 │         4 │        0 │    0 │\n",
      "│\u001b[1m Hazardous \u001b[0m│    6 │       415 │        0 │   26 │\n",
      "│\u001b[1m  Moderate \u001b[0m│    0 │         0 │      128 │   32 │\n",
      "│\u001b[1m      Poor \u001b[0m│    0 │        31 │       20 │  250 │\n",
      "└───────────┴──────┴───────────┴──────────┴──────┘\n",
      "\n",
      "===== Running ANN with topology = [6, 256, 512] =====\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Statistics\n",
    "using Plots\n",
    "using MLJ\n",
    "using MLJBase\n",
    "using MLJModels\n",
    "using DataFrames\n",
    "using PrettyTables\n",
    "\n",
    "# ---------------------- PRINT RESULTS ----------------------\n",
    "function printANNResult(model, hyperparams, metrics, outdim, class_labels)\n",
    "    accuracy, error_rate, recall, specificity, ppv, npv, f1, cm = metrics\n",
    "\n",
    "    println(\"\\n=====================================================\")\n",
    "    println(\" Model: $model   | PCA outdim = $outdim \")\n",
    "    println(\" Hyperparameters: $hyperparams\")\n",
    "    println(\"=====================================================\")\n",
    "\n",
    "    println(rpad(\" Accuracy\", 25), \": \", round(accuracy, digits=4))\n",
    "    println(rpad(\" Error Rate\", 25), \": \", round(error_rate, digits=4))\n",
    "    println(rpad(\" Sensitivity/Recall\", 25), \": \", round(recall, digits=4))\n",
    "    println(rpad(\" Specificity\", 25), \": \", round(specificity, digits=4))\n",
    "    println(rpad(\" PPV\", 25), \": \", round(ppv, digits=4))\n",
    "    println(rpad(\" NPV\", 25), \": \", round(npv, digits=4))\n",
    "    println(rpad(\" F1 Score\", 25), \": \", round(f1, digits=4))\n",
    "\n",
    "    println(\"\\nConfusion Matrix:\")\n",
    "    println(cm)\n",
    "    println(\"=====================================================\\n\")\n",
    "\n",
    "    cm_df = DataFrame(cm, :auto)\n",
    "    PrettyTables.pretty_table(cm_df; header=class_labels, row_labels=class_labels)\n",
    "end\n",
    "\n",
    "# ---------------------- SAFE ACCURACY ----------------------\n",
    "accuracy_score(pred::Vector{Int}, truth::Vector{Int}) = mean(pred .== truth)\n",
    "accuracy = accuracy_score\n",
    "const Losses = Flux\n",
    "\n",
    "# ---------------------- PCA ----------------------\n",
    "PCA = @load PCA pkg=MultivariateStats\n",
    "dims = [6, 7, 8]\n",
    "\n",
    "# ---------------------- BASE HIDDEN LAYERS ----------------------\n",
    "base_hidden_layers = [\n",
    "    [128, 256],\n",
    "    [256, 512]\n",
    "]\n",
    "\n",
    "learningRate = 0.01\n",
    "epochs = 200\n",
    "results = Dict{String, Dict{Int, Tuple{Vector{Float32}, Vector{Float32}, Vector{Float32}}}}()\n",
    "\n",
    "class_labels = unique(trainingTargets)\n",
    "labels = string.(class_labels)\n",
    "\n",
    "println(\"\\n==== Starting ANN Experiments ====\\n\")\n",
    "\n",
    "# ---------------------- MAIN LOOP ----------------------\n",
    "for outdim in dims\n",
    "    # --- PCA transformation ---\n",
    "    pca_model = PCA(maxoutdim = outdim)\n",
    "    pca_mach = machine(pca_model, MLJ.table(trainingInputs))\n",
    "    MLJ.fit!(pca_mach)\n",
    "\n",
    "    pca_train = MLJBase.matrix(MLJ.transform(pca_mach, MLJ.table(trainingInputs)))\n",
    "    pca_val   = MLJBase.matrix(MLJ.transform(pca_mach, MLJ.table(valInputs)))\n",
    "    pca_test  = MLJBase.matrix(MLJ.transform(pca_mach, MLJ.table(testInputs)))\n",
    "\n",
    "    # --- One-hot encode targets ---\n",
    "    trainingTargetsOH = oneHotEncoding(trainingTargets, class_labels)\n",
    "    valTargetsOH      = oneHotEncoding(valTargets, class_labels)\n",
    "    testTargetsOH     = oneHotEncoding(testTargets, class_labels)\n",
    "\n",
    "    # --- Create full hidden layers including PCA dim ---\n",
    "    hidden_layers_list = [[outdim; hl...] for hl in base_hidden_layers]\n",
    "\n",
    "    for topology in hidden_layers_list\n",
    "        topo_key = string(topology)\n",
    "        results[topo_key] = Dict{Int, Tuple{Vector{Float32}, Vector{Float32}, Vector{Float32}}}()\n",
    "\n",
    "        println(\"\\n===== Running ANN with topology = $topology =====\")\n",
    "\n",
    "        # --- Train ANN ---\n",
    "        finalAnn, trainLoss, valLoss, testLoss = trainClassANN(\n",
    "            topology,\n",
    "            (pca_train, trainingTargetsOH),\n",
    "            validationDataset = (pca_val, valTargetsOH),\n",
    "            testDataset       = (pca_test, testTargetsOH),\n",
    "            maxEpochs = epochs,\n",
    "            learningRate = learningRate,\n",
    "            showText = false\n",
    "        )\n",
    "\n",
    "        # --- Store losses ---\n",
    "        results[topo_key][outdim] = (trainLoss, valLoss, testLoss)\n",
    "\n",
    "        # --- Classification ---\n",
    "        # testOutputs = finalAnn(pca_test')         # size: classes × samples\n",
    "        # predicted_indices = map(i -> argmax(i), eachcol(testOutputs))\n",
    "        # true_indices      = map(i -> argmax(i), eachrow(testTargetsOH))\n",
    "        testOutputs = finalAnn(pca_test')\n",
    "        testPredictions = classifyOutputs(testOutputs')  # boolean matrix\n",
    "\n",
    "\n",
    "        # --- Metrics ---\n",
    "        cm_metrics = confusionMatrix(testPredictions, testTargetsOH)\n",
    "        cm = cm_metrics[end]\n",
    "\n",
    "        printANNResult(\n",
    "            topology,\n",
    "            Dict(\"learningRate\" => learningRate, \"epochs\" => epochs, \"PCA_outdim\" => outdim),\n",
    "            cm_metrics,\n",
    "            outdim,\n",
    "            label_names\n",
    "        )\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"\\n==== Finished All Experiments ====\\n\")\n",
    "\n",
    "# ---------------------- PLOT LOSSES ----------------------\n",
    "for (topology, dims_dict) in results\n",
    "    for (outdim, (trainLoss, valLoss, testLoss)) in dims_dict\n",
    "        epoch_vec = 0:length(trainLoss)-1\n",
    "        p = plot(epoch_vec, trainLoss, label=\"Train Loss\", lw=2, marker=:circle)\n",
    "\n",
    "        if !isempty(valLoss)\n",
    "            plot!(p, epoch_vec, valLoss, label=\"Validation Loss\",\n",
    "                  lw=2, linestyle=:dash, marker=:diamond)\n",
    "        end\n",
    "\n",
    "        if !isempty(testLoss)\n",
    "            plot!(p, epoch_vec, testLoss, label=\"Test Loss\",\n",
    "                  lw=2, linestyle=:dot, marker=:star)\n",
    "        end\n",
    "\n",
    "        xlabel!(\"Epoch\")\n",
    "        ylabel!(\"Loss\")\n",
    "        title!(\"Loss Evolution - Topology $(topology) - PCA $outdim\")\n",
    "        plot!(legend=:topright)\n",
    "        display(p)\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a3b79f",
   "metadata": {},
   "source": [
    "# SVM/KNN/DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7960b3",
   "metadata": {},
   "source": [
    "## Prepare data for SVM/KNN/DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b98e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainIdx, testIdx = holdOut(N, 0.3)\n",
    "println(\"Train indices: \", length(trainIdx))\n",
    "println(\"Test indices: \", length(testIdx))\n",
    "println(\"df size: \", size(df))\n",
    "\n",
    "trainingInputs  = inputs[trainIdx, :]\n",
    "testInputs      = inputs[testIdx, :]\n",
    "\n",
    "trainingTargets = targets[trainIdx]\n",
    "testTargets     = targets[testIdx]\n",
    "\n",
    "println(\"\\n\\nFirst 5 targets:\")\n",
    "println(targets[1:5])\n",
    "\n",
    "println(\"Training inputs (first 5 rows):\")\n",
    "for i in 1:5\n",
    "    println(trainingInputs[i, :])\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "println(\"\\n\\n=========== Normalizing Inputs ===========\")\n",
    "\n",
    "# Compute normalization parameters from TRAINING set only\n",
    "normParams = calculateMinMaxNormalizationParameters(trainingInputs)\n",
    "\n",
    "# Normalize training set IN PLACE\n",
    "normalizeMinMax!(trainingInputs, normParams)\n",
    "\n",
    "# Normalize test set in place\n",
    "#valInputs_normalized = normalizeMinMax(valInputs, normParams)\n",
    "normalizeMinMax!(testInputs, normParams)\n",
    "\n",
    "\n",
    "println(\"\\nTraining inputs after normalization (first 5 rows):\")\n",
    "for i in 1:5\n",
    "    println(trainingInputs[i, :])\n",
    "end\n",
    "\n",
    "println(\"\\nTest inputs after normalization (first 5 rows):\")\n",
    "for i in 1:5\n",
    "    println(testInputs[i, :])\n",
    "end\n",
    "\n",
    "# Convert to float32 for Flux compatibility\n",
    "trainingInputs = Float32.(trainingInputs)\n",
    "testInputs = Float32.(testInputs)\n",
    "\n",
    "# Clip values to [0,1] after normalization\n",
    "testInputs .= clamp.(testInputs, 0f0, 1f0)\n",
    "testInputs .= clamp.(testInputs, 0f0, 1f0)\n",
    "\n",
    "# Convert directly to DataFrames for MLJ\n",
    "train_df = DataFrame(trainingInputs, :auto)\n",
    "test_df  = DataFrame(testInputs, :auto)\n",
    "\n",
    "# Values should only fall within [0,1]\n",
    "@assert(all(minimum(trainingInputs, dims=1) .== 0))\n",
    "@assert(all(maximum(trainingInputs, dims=1) .== 1))\n",
    "@assert(all(minimum(testInputs, dims=1) .>= 0))\n",
    "@assert(all(maximum(testInputs, dims=1) .<= 1))\n",
    "\n",
    "\n",
    "println(\"Train inputs range per feature: \", (minimum(trainingInputs, dims=1), maximum(trainingInputs, dims=1)))\n",
    "println(\"Test inputs range per feature: \", (minimum(testInputs, dims=1), maximum(testInputs, dims=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c80cbd",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da3038",
   "metadata": {},
   "source": [
    "## function printResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c523767",
   "metadata": {},
   "outputs": [],
   "source": [
    "function printResult(model, hyperparams, metrics,outdim,class_labels)\n",
    "    # Unpack metrics returned by confusionMatrix\n",
    "    accuracy, error_rate, recall, specificity, ppv, npv, f1, cm = metrics\n",
    "\n",
    "    println(\"\\n=====================================================\")\n",
    "    println(\" Model: $model outdim $outdim \")\n",
    "    println(\" Hyperparameters: $hyperparams\")\n",
    "    println(\"=====================================================\")\n",
    "\n",
    "    println(rpad(\" Accuracy\", 25), \": \", round(accuracy, digits=4))\n",
    "    println(rpad(\" Error Rate\", 25), \": \", round(error_rate, digits=4))\n",
    "    println(rpad(\" Sensitivity/Recall\", 25), \": \", round(recall, digits=4))\n",
    "    println(rpad(\" Specificity\", 25), \": \", round(specificity, digits=4))\n",
    "    println(rpad(\" PPV\", 25), \": \", round(ppv, digits=4))\n",
    "    println(rpad(\" NPV\", 25), \": \", round(npv, digits=4))\n",
    "    println(rpad(\" F1 Score\", 25), \": \", round(f1, digits=4))\n",
    "\n",
    "    println(\"\\nConfusion Matrix:\")\n",
    "    println(cm)\n",
    "    println(\"=====================================================\\n\")\n",
    "    cm_df = DataFrame(cm, :auto)\n",
    "    PrettyTables.pretty_table(cm_df; header=class_labels, row_labels=class_labels)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d56381",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab91f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ, LIBSVM, CategoricalArrays, MLJBase, DataFrames\n",
    "\n",
    "# Init PCA\n",
    "PCA        = @load PCA pkg = MultivariateStats\n",
    "dims = [6,7,8]\n",
    "\n",
    "# --- Default hyperparameters ---\n",
    "default_svm = Dict(\n",
    "    \"gamma\"  => 1.0,\n",
    "    \"degree\" => Int32(3),\n",
    "    \"coef0\"  => 0.0\n",
    ")\n",
    "\n",
    "# --- Hyperparameter search space ---\n",
    "svm_search_space = [\n",
    "    Dict(\"kernel\"=>\"linear\",  \"C\"=>0.1),\n",
    "    Dict(\"kernel\"=>\"linear\",  \"C\"=>1.0),\n",
    "    Dict(\"kernel\"=>\"linear\",  \"C\"=>10.0),\n",
    "    Dict(\"kernel\"=>\"rbf\",     \"C\"=>1.0, \"gamma\"=>2.0),\n",
    "    Dict(\"kernel\"=>\"rbf\",     \"C\"=>10.0,\"gamma\"=>0.5),\n",
    "    Dict(\"kernel\"=>\"sigmoid\", \"C\"=>1.0, \"gamma\"=>1.0),\n",
    "    Dict(\"kernel\"=>\"poly\",    \"C\"=>1.0, \"degree\"=>3, \"gamma\"=>1.0),\n",
    "    Dict(\"kernel\"=>\"poly\",    \"C\"=>5.0, \"degree\"=>4, \"gamma\"=>0.5),\n",
    "]\n",
    "\n",
    "# --- Convert targets ---\n",
    "train_y_cat = categorical(vec(trainingTargets))\n",
    "test_y_cat  = categorical(vec(testTargets))\n",
    "\n",
    "# --- Container for results ---\n",
    "svm_results = []\n",
    "\n",
    "# --- Wrap PCA / raw data as DataFrames ---\n",
    "# Assume train_df and test_df are already prepared DataFrames of features\n",
    "# e.g., train_df = DataFrame(pca_train, :auto), test_df = DataFrame(pca_test, :auto)\n",
    "\n",
    "for hp in svm_search_space\n",
    "    println(\"\\n=== SVM experiment: kernel=$(hp[\"kernel\"]) C=$(hp[\"C\"]) ===\")\n",
    "\n",
    "    # Map string kernels to LIBSVM.Kernel enums\n",
    "    kernel_enum = hp[\"kernel\"] == \"linear\"  ? LIBSVM.Kernel.Linear  :\n",
    "                  hp[\"kernel\"] == \"rbf\"     ? LIBSVM.Kernel.RadialBasis :\n",
    "                  hp[\"kernel\"] == \"sigmoid\" ? LIBSVM.Kernel.Sigmoid :\n",
    "                  hp[\"kernel\"] == \"poly\"    ? LIBSVM.Kernel.Polynomial :\n",
    "                  error(\"Unsupported kernel: $(hp[\"kernel\"])\")\n",
    "\n",
    "    cost   = Float64(hp[\"C\"])\n",
    "    gamma  = Float64(get(hp, \"gamma\", 1.0))\n",
    "    degree = Int32(get(hp, \"degree\", 3))\n",
    "    coef0  = Float64(get(hp, \"coef0\", 0.0))\n",
    "\n",
    "    # Load MLJ SVM model\n",
    "    SVM_model = @load SVC pkg=LIBSVM verbosity=0\n",
    "    model = SVM_model(\n",
    "        kernel = kernel_enum,\n",
    "        cost   = cost,\n",
    "        gamma  = gamma,\n",
    "        degree = degree,\n",
    "        coef0  = coef0\n",
    "    )\n",
    "    for outdim in dims\n",
    "        println(\"\\n===== Running PCA with maxoutdim = $outdim =====\")\n",
    "\n",
    "        # ------ Fit PCA ------\n",
    "        pca_model = PCA(maxoutdim = outdim)\n",
    "        pca_mach = machine(pca_model, MLJ.table(trainingInputs))\n",
    "        MLJ.fit!(pca_mach)\n",
    "\n",
    "        # Transform data\n",
    "        pca_train = MLJ.transform(pca_mach, MLJ.table(trainingInputs))\n",
    "        pca_test  = MLJ.transform(pca_mach, MLJ.table(testInputs))\n",
    "\n",
    "        # Convert to DataFrames\n",
    "        pca_train_df = DataFrame(MLJBase.matrix(pca_train), :auto)\n",
    "        pca_test_df  = DataFrame(MLJBase.matrix(pca_test), :auto)\n",
    "\n",
    "        # Fit SVM on PCA data\n",
    "        svm_mach = machine(model, pca_train_df, train_y_cat)\n",
    "        MLJ.fit!(svm_mach)\n",
    "\n",
    "        # Predict\n",
    "        ŷ = MLJ.predict(svm_mach, pca_test_df)\n",
    "        y_pred = CategoricalArray(ŷ)\n",
    "\n",
    "\n",
    "\n",
    "        # --- Metrics ---\n",
    "        # --- Compute metrics using your function ---\n",
    "        accuracy, error_rate, recall, specificity, ppv, npv, f1, cm =\n",
    "            confusionMatrix(y_pred, test_y_cat)\n",
    "\n",
    "        #println(\"Accuracy = \", round(accuracy, digits=4))\n",
    "\n",
    "        push!(svm_results, (\n",
    "            model = :SVC,\n",
    "            hyperparams = hp,\n",
    "            metrics = (accuracy, error_rate, recall, specificity, ppv, npv, f1, cm),\n",
    "            maxoutdim = outdim\n",
    "        ))\n",
    "    end\n",
    "\n",
    "\n",
    "end\n",
    "\n",
    "results = Dict(:SVC => svm_results)\n",
    "println(\"\\n===== Grid search finished =====\")\n",
    "\n",
    "for entry in results[:SVC]\n",
    "    printResult(entry.model, entry.hyperparams, entry.metrics,entry.maxoutdim,labels)\n",
    "    #printExperimentResult(:SVC, Dict(\"C\"=>0.1, \"kernel\"=>\"linear\"), results, class_labels=labels)\n",
    "end\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d2af0a",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d93bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# LOAD PCA\n",
    "# ============================\n",
    "# Init PCA\n",
    "PCA        = @load PCA pkg = MultivariateStats\n",
    "dims = [6,7,8]\n",
    "\n",
    "############# 3. DECISION TREES (6 depths) #############\n",
    "default_dt = Dict(\n",
    "    \"rng\" => Random.MersenneTwister(1)\n",
    ")\n",
    "\n",
    "dt_search_space = [\n",
    "    Dict(\"max_depth\"=>2),\n",
    "    Dict(\"max_depth\"=>3),\n",
    "    Dict(\"max_depth\"=>4),\n",
    "    Dict(\"max_depth\"=>5),\n",
    "    Dict(\"max_depth\"=>6),\n",
    "    Dict(\"max_depth\"=>8)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# --- Convert targets ---\n",
    "\n",
    "# --- Container for results ---\n",
    "dt_results = []\n",
    "\n",
    "# --- Wrap PCA / raw data as DataFrames ---\n",
    "# Assume train_df and test_df are already prepared DataFrames of features\n",
    "\n",
    "# ----------------------------\n",
    "# DECISION TREE GRID SEARCH\n",
    "# ----------------------------\n",
    "for hp in dt_search_space\n",
    "    println(\"\\n=== Decision Tree experiment: max_depth=$(hp[\"max_depth\"]) ===\")\n",
    "    \n",
    "    # Merge default hyperparameters with current hp\n",
    "    full_hp = merge(default_dt, hp)\n",
    "    \n",
    "    # Load DecisionTreeClassifier\n",
    "    DT_model = @load DecisionTreeClassifier pkg=DecisionTree verbosity=0\n",
    "    model = DT_model(\n",
    "        max_depth = full_hp[\"max_depth\"],\n",
    "        rng       = full_hp[\"rng\"]\n",
    "    )\n",
    "    \n",
    "    # # --- Train machine ---\n",
    "    # mach = machine(model, train_df, train_y_cat)\n",
    "    # MLJ.fit!(mach)\n",
    "    \n",
    "    # # --- Predict ---\n",
    "    # ŷ = MLJ.predict(mach, test_df)\n",
    "    # y_pred = CategoricalArray(mode.(ŷ))  # convert MLJ probabilistic predictions to class labels\n",
    "\n",
    "    for outdim in dims\n",
    "        println(\"\\n===== Running PCA with maxoutdim = $outdim =====\")\n",
    "        # ------ Fit PCA ------\n",
    "        pca_model = PCA(maxoutdim = outdim)\n",
    "        pca_mach = machine(pca_model, MLJ.table(trainingInputs))\n",
    "        MLJ.fit!(pca_mach)\n",
    "\n",
    "        # Transform data\n",
    "        pca_train = MLJ.transform(pca_mach, MLJ.table(trainingInputs))\n",
    "        pca_test  = MLJ.transform(pca_mach, MLJ.table(testInputs))\n",
    "\n",
    "        # Convert to DataFrames\n",
    "        pca_train_df = DataFrame(MLJBase.matrix(pca_train), :auto)\n",
    "        pca_test_df  = DataFrame(MLJBase.matrix(pca_test), :auto)\n",
    "\n",
    "        # Fit DT on PCA data\n",
    "        dt_mach = machine(model, pca_train_df, train_y_cat)\n",
    "        MLJ.fit!(dt_mach)\n",
    "\n",
    "        # Predict\n",
    "        ŷ = MLJ.predict(dt_mach, pca_test_df)\n",
    "        y_pred = CategoricalArray(mode.(ŷ))  # convert MLJ probabilistic predictions to class labels\n",
    "\n",
    "\n",
    "\n",
    "        # --- Compute metrics ---\n",
    "        accuracy, error_rate, recall, specificity, ppv, npv, f1, cm =\n",
    "            confusionMatrix(y_pred, test_y_cat)\n",
    "        \n",
    "        println(\"Accuracy = \", round(accuracy, digits=4))\n",
    "    \n",
    "        push!(dt_results, (\n",
    "            model = :DecisionTree,\n",
    "            hyperparams = hp,\n",
    "            metrics = (accuracy, error_rate, recall, specificity, ppv, npv, f1, cm),\n",
    "            maxoutdim = outdim))\n",
    "    end\n",
    "end\n",
    "\n",
    "# Store results in dict\n",
    "results[:DecisionTree] = dt_results\n",
    "println(\"\\n===== Grid search finished =====\")\n",
    "\n",
    "# ----------------------------\n",
    "# Print all results\n",
    "# ----------------------------\n",
    "for entry in results[:DecisionTree]\n",
    "    printResult(entry.model, entry.hyperparams, entry.metrics, entry.maxoutdim,labels)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c083ce",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init PCA\n",
    "PCA        = @load PCA pkg = MultivariateStats\n",
    "dims = [6,7]\n",
    "############# 4. kNN (6 values) #############\n",
    "knn_search_space = [\n",
    "    Dict(\"K\"=>1),\n",
    "    Dict(\"K\"=>3),\n",
    "    Dict(\"K\"=>5),\n",
    "    Dict(\"K\"=>7),\n",
    "    Dict(\"K\"=>9),\n",
    "    Dict(\"K\"=>11)\n",
    "]\n",
    "\n",
    "# --- Convert targets ---\n",
    "train_y_cat = categorical(vec(trainingTargets))\n",
    "test_y_cat  = categorical(vec(testTargets))\n",
    "\n",
    "# --- Container for results ---\n",
    "knn_results = []\n",
    "\n",
    "# --- kNN hyperparameter search space ---\n",
    "knn_search_space = [\n",
    "    Dict(\"K\"=>1),\n",
    "    Dict(\"K\"=>3),\n",
    "    Dict(\"K\"=>5),\n",
    "    Dict(\"K\"=>7),\n",
    "    Dict(\"K\"=>9),\n",
    "    Dict(\"K\"=>11)\n",
    "]\n",
    "\n",
    "# --- Loop over K values ---\n",
    "KNN_model_type = @load KNNClassifier pkg=NearestNeighborModels verbosity=0\n",
    "\n",
    "for hp in knn_search_space\n",
    "    println(\"\\n=== kNN experiment: K=$(hp[\"K\"]) ===\")\n",
    "    \n",
    "    K = Int(hp[\"K\"])\n",
    "    \n",
    "    # Load MLJ KNN model\n",
    "    model = KNN_model_type(K=K)\n",
    "    for outdim in dims\n",
    "        println(\"\\n===== Running PCA with maxoutdim = $outdim =====\")\n",
    "        # ------ Fit PCA ------\n",
    "        pca_model = PCA(maxoutdim = outdim)\n",
    "        pca_mach = machine(pca_model, MLJ.table(trainingInputs))\n",
    "        MLJ.fit!(pca_mach)\n",
    "\n",
    "        # Transform data\n",
    "        pca_train = MLJ.transform(pca_mach, MLJ.table(trainingInputs))\n",
    "        pca_test  = MLJ.transform(pca_mach, MLJ.table(testInputs))\n",
    "\n",
    "        # Convert to DataFrames\n",
    "        pca_train_df = DataFrame(MLJBase.matrix(pca_train), :auto)\n",
    "        pca_test_df  = DataFrame(MLJBase.matrix(pca_test), :auto)\n",
    "\n",
    "        # Fit KNN on PCA data\n",
    "        dt_mach = machine(model, pca_train_df, train_y_cat)\n",
    "        MLJ.fit!(dt_mach)\n",
    "\n",
    "        # Predict\n",
    "        ŷ = MLJ.predict(dt_mach, pca_test_df)\n",
    "        y_pred = CategoricalArray(mode.(ŷ))  # convert MLJ probabilistic predictions to class labels\n",
    "        # # --- Train machine ---\n",
    "        # mach = machine(model, train_df, train_y_cat)\n",
    "        # MLJ.fit!(mach)\n",
    "        \n",
    "        # # --- Predict ---\n",
    "        # ŷ = MLJ.predict(mach, test_df)              # probabilistic predictions\n",
    "        # y_pred = CategoricalArray(mode.(ŷ))         # convert to class labels\n",
    "        \n",
    "        # --- Compute metrics ---\n",
    "        accuracy, error_rate, recall, specificity, ppv, npv, f1, cm =\n",
    "             confusionMatrix(y_pred, test_y_cat)\n",
    "        \n",
    "        println(\"Accuracy = \", round(accuracy, digits=4))\n",
    "        \n",
    "        # --- Save results ---\n",
    "        push!(knn_results, (\n",
    "             model = :kNN,\n",
    "             hyperparams = hp,\n",
    "             metrics = (accuracy, error_rate, recall, specificity, ppv, npv, f1, cm),\n",
    "             maxoutdim = outdim\n",
    "         ))\n",
    "    end\n",
    "        \n",
    "end\n",
    "\n",
    "# --- Store all results ---\n",
    "results[:kNN] = knn_results\n",
    "\n",
    "# --- Print results ---\n",
    "for entry in results[:kNN]\n",
    "    printResult(entry.model, entry.hyperparams, entry.metrics,entry.maxoutdim, labels)\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.6",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
